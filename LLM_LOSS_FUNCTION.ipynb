{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgWxaJI8nPet",
        "outputId": "2f1a6d93-1739-4e5c-d551-d14f566f269b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self,emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps=1e-5\n",
        "    self.scale= nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift= nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self,x):\n",
        "    mean= x.mean(dim=-1,keepdim=True)\n",
        "    var= x.var(dim=-1,keepdim=True,unbiased=False)\n",
        "    norm_x= (x-mean)/torch.sqrt(var+self.eps)\n",
        "    return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "TqaKv5ZBm3Mv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert(d_out%num_heads==0),\\\n",
        "    \"d_out must be divisible by num_heads\"\n",
        "    self.d_out= d_out\n",
        "    self.num_heads= num_heads\n",
        "    self.head_dim= d_out//num_heads\n",
        "    self.W_query= nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "    self.W_key= nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "    self.W_value= nn.Linear(d_in,d_out,bias=qkv_bias)\n",
        "    self.out_proj=nn.Linear(d_out,d_out) #linear layer to combine head outputs\n",
        "    self.dropout= nn.Dropout(dropout)\n",
        "    self.register_buffer(\"mask\",torch.triu(torch.ones(context_length,context_length),diagonal=1))\n",
        "\n",
        "  def forward(self,x):\n",
        "    b,num_tokens,d_in= x.shape\n",
        "    keys= self.W_key(x) # (b,num_tokens,d_out)\n",
        "    queries= self.W_query(x)\n",
        "    values= self.W_value(x)\n",
        "    # we implicitly split matrix by adding num_heads dim\n",
        "    keys= keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    queries= queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    values= values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    #transpose (b,num_tokens,num_heads,head_dim)->(b,num_heads,num_tokens,head_dim)\n",
        "    #This dimension helps in parallel computation\n",
        "    keys= keys.transpose(1,2)\n",
        "    queries=queries.transpose(1,2)\n",
        "    values= values.transpose(1,2)\n",
        "    attn_scores= queries @ keys.transpose(2,3) #(b,num_heads,num_tokens,num_tokens)\n",
        "    mask_bool= self.mask.bool()[:num_tokens,:num_tokens]\n",
        "    attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
        "    attn_weights= torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
        "    attn_weights= self.dropout(attn_weights)\n",
        "    #context vec before tanspose (b,num_heads,num_token,head_dim)\n",
        "    #after transpose (b,num_tokens,num_heads,head_dim)\n",
        "    #merging the heads back\n",
        "    context_vec= (attn_weights @ values).transpose(1,2)\n",
        "    context_vec= context_vec.contiguous().view(b,num_tokens,self.d_out)\n",
        "    context_vec= self.out_proj(context_vec)\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "NOdjtzn1nIzN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi)))*(x+0.044715*torch.pow(x,3)))\n"
      ],
      "metadata": {
        "id": "Fvb8CtCcnmwS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.layers= nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "M2qRhA6-nhMv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.att= MultiHeadAttention(\n",
        "        d_in= cfg[\"emb_dim\"],\n",
        "        d_out= cfg[\"emb_dim\"],\n",
        "        context_length= cfg[\"context_length\"],\n",
        "        num_heads= cfg[\"n_heads\"],\n",
        "        dropout= cfg[\"drop_rate\"],\n",
        "        qkv_bias= cfg[\"qkv_bias\"]\n",
        "    )\n",
        "    self.ff= FeedForward(cfg)\n",
        "    self.norm1= LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2= LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut= nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self,x):\n",
        "    shortcut=x\n",
        "    x= self.norm1(x)\n",
        "    x= self.att(x)\n",
        "    x= self.drop_shortcut(x)\n",
        "    x=shortcut+x\n",
        "\n",
        "    shortcut=x\n",
        "    x= self.norm2(x)\n",
        "    x= self.ff(x)\n",
        "    x= self.drop_shortcut(x)\n",
        "    x=x+shortcut\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "CWfeSKUamxTn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tY_5r6ugl3c2"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "1QCgKgmvn4MM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model,idx,max_new_tokens,context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond= idx[:,-context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits= model(idx_cond)\n",
        "    logits= logits[:,-1,:]\n",
        "    probas= torch.softmax(logits,dim=-1)\n",
        "    idx_next= torch.argmax(probas,dim=-1,keepdim=True)\n",
        "    idx= torch.cat((idx,idx_next),dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "vfxo0RJWppmW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "  encoded= tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor= torch.tensor(encoded).unsqueeze(0) #Adds a dimension of size 1 at the specified position.\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "  flat= token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context= \"Every effort moves you\"\n",
        "tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids= generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context,tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size= GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymQKN-kUoF-5",
        "outputId": "93077c04-0244-4df3-cfbd-014799a8d796"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you Gambleя Myr PillTeen dresses Psychology wor ridic Jehovah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ],
      "metadata": {
        "id": "_BnJbOt9qhwv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  logits= model(inputs)\n",
        "\n",
        "probas= torch.softmax(logits,dim=-1)\n",
        "print(probas.shape)\n",
        "print(probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz2q7Bj3qh6C",
        "outputId": "0d34a3eb-1e63-4aa3-d19c-9350da2777f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n",
            "tensor([[[1.8680e-05, 1.8059e-05, 3.3356e-05,  ..., 1.7160e-05,\n",
            "          1.1289e-05, 1.1339e-05],\n",
            "         [6.3086e-06, 1.7280e-05, 1.6449e-05,  ..., 1.4804e-05,\n",
            "          1.5839e-05, 4.7729e-06],\n",
            "         [1.6625e-05, 1.1277e-05, 1.6356e-05,  ..., 7.5937e-06,\n",
            "          7.7565e-06, 2.1299e-05]],\n",
            "\n",
            "        [[4.7255e-06, 2.3671e-05, 3.2888e-05,  ..., 9.8001e-06,\n",
            "          8.0078e-06, 3.5715e-05],\n",
            "         [8.4019e-06, 1.9870e-05, 8.0899e-06,  ..., 8.6421e-06,\n",
            "          1.6314e-05, 9.8128e-06],\n",
            "         [2.4459e-05, 8.3489e-06, 1.1318e-05,  ..., 7.4059e-06,\n",
            "          1.1175e-05, 3.0409e-05]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = torch.argmax(probas,dim=-1,keepdim=True)\n",
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewP9LRZksjCc",
        "outputId": "5b533dd4-c6f9-4e38-9f74-4849fac767d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 2210],\n",
            "         [39383],\n",
            "         [17114]],\n",
            "\n",
            "        [[32834],\n",
            "         [13031],\n",
            "         [14003]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_no=0\n",
        "target_probas_1= probas[batch_no,[0,1,2],targets[batch_no]]\n",
        "print(target_probas_1)\n",
        "\n",
        "batch_no=1\n",
        "target_probas_2= probas[batch_no,[0,1,2],targets[batch_no]]\n",
        "print(target_probas_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKcdvQjasjsW",
        "outputId": "2780ab99-62e4-46af-c4f3-e1b803b2ce66"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.9408e-05, 1.2241e-05, 8.7907e-06])\n",
            "tensor([2.9447e-05, 8.4477e-06, 2.7971e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xacV5qq4T7w_",
        "outputId": "4d55765a-e135-4f5b-819c-83a036e12f31"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-10.4342, -11.3107, -11.6418, -10.4329, -11.6816, -10.4843])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVznwgzJT760",
        "outputId": "f73d5914-ef7b-43f3-c06a-4c2bcd424227"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.9976)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMZsLFI9T7-Y",
        "outputId": "d16fc7c4-8f3f-439f-843d-6040fd4353cb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.9976)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Whz24lUKCY",
        "outputId": "3adf35e0-7f53-43b3-95d0-21b65ba4da26"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mXqs_r7UUZJ",
        "outputId": "e5b77da7-d378-432a-9602-1aa62359ff75"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.9976)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsxwQQhZVA40",
        "outputId": "849f71a5-1f65-4d3f-c7a4-34d0b548e9ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(59731.5625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "file_path= \"/content/the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "if not os.path.exists(file_path):\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    text_data= response.read().decode('utf-8')\n",
        "  with open(file_path,\"w\",encoding='utf-8') as file:\n",
        "    file.write(text_data)\n",
        "else:\n",
        "  with open(file_path,\"r\",encoding=\"utf-8\") as file:\n",
        "    text_data= file.read()"
      ],
      "metadata": {
        "id": "9zCUWB1QVKF5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_data[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izvdLTmUDupr",
        "outputId": "0eb19cb4-7374-4d29-a2d6-4c8488047b13"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL4RqfmGDuwD",
        "outputId": "51232a8d-b35e-464b-e288-7d01cdf3a310"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
        "total_characters= len(text_data)\n",
        "total_tokens= len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\",total_characters)\n",
        "print(\"Tokens:\",total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWMidrFPDuss",
        "outputId": "af233c3a-56bf-47ce-a32f-e4c8ff26db1f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input_ids=[]\n",
        "    self.target_ids=[]\n",
        "\n",
        "    token_ids= tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      input_chunk= token_ids[i:i+max_length]\n",
        "      target_chunk= token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx],self.target_ids[idx]"
      ],
      "metadata": {
        "id": "yIANcl-6ExTx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
        "  tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset= GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
        "  dataloader= DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=drop_last,num_workers=num_workers)\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "phCBbM6eExjZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}"
      ],
      "metadata": {
        "id": "SkgDh0jCExnQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio= 0.90\n",
        "split_idx= int(train_ratio*len(text_data))\n",
        "train_data= text_data[:split_idx]\n",
        "val_data= text_data[split_idx:]\n",
        "train_loader= create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "val_loader= create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"]\n",
        ")"
      ],
      "metadata": {
        "id": "kpY3JSx5Exqx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ],
      "metadata": {
        "id": "8Ejl5oSqHrLO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Loader:\")\n",
        "for x,y in train_loader:\n",
        "  print(x.shape,y.shape)\n",
        "\n",
        "print(\"\\nValidation Loader:\")\n",
        "for x,y in val_loader:\n",
        "  print(x.shape,y.shape)\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVVIWohaHVwT",
        "outputId": "637e4836-64c0-48a2-d7b4-cc736b49c8b0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation Loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "9\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens=0\n",
        "for input_batch, target_batch in train_loader:\n",
        "  train_tokens+=input_batch.numel()\n",
        "\n",
        "val_tokens=0\n",
        "for input_batch,target_batch in val_loader:\n",
        "  val_tokens+=input_batch.numel()\n",
        "\n",
        "print(\"Training Tokens:\",train_tokens)\n",
        "print(\"Validation Tokens:\",val_tokens)\n",
        "print(\"All Tokens:\",train_tokens+val_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmHB_iK8HWPa",
        "outputId": "308cc998-5714-4b15-de7d-dafb13854542"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Tokens: 4608\n",
            "Validation Tokens: 512\n",
            "All Tokens: 5120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TdTlO7wK9Op",
        "outputId": "227cc51f-f389-46cd-f830-c972607946ca"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch,target_batch,model,device):\n",
        "  input_batch,target_batch= input_batch.to(device), target_batch.to(device)\n",
        "  logits= model(input_batch)\n",
        "  loss= torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
        "  return loss #Calculates the cross-entropy loss for one batch of data.\n",
        "\n",
        "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
        "  #Calculates the average loss over multiple batches from a DataLoader.\n",
        "  total_loss=0\n",
        "  if len(data_loader)==0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches= len(data_loader)\n",
        "  else:\n",
        "    num_batches= min(len(data_loader),num_batches)\n",
        "  for i,(input_batch,target_batch) in enumerate(data_loader):\n",
        "    if i<num_batches:\n",
        "      loss= calc_loss_batch(input_batch,target_batch,model,device)\n",
        "      total_loss+=loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss/num_batches"
      ],
      "metadata": {
        "id": "UfqxhXrYK97L"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device= torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "  train_loss= calc_loss_loader(train_loader,model,device)\n",
        "  val_loss= calc_loss_loader(val_loader,model,device)\n",
        "\n",
        "print(\"Training loss:\",train_loss)\n",
        "print(\"Validation Loss:\",val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qr7xQEhwnzf",
        "outputId": "f9d828b4-df2e-4275-8303-cf47b1c00410"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.998977767096626\n",
            "Validation Loss: 10.983667373657227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss= calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
        "    val_loss= calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "E3_jQwyWz9jo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model,tokenizer,device,start_context):\n",
        "  model.eval()\n",
        "  context_size= model.pos_emb.weight.shape[0]\n",
        "  encoded= text_to_token_ids(start_context,tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids= generate_text_simple(model,idx=encoded,max_new_tokens=50,context_size=context_size)\n",
        "  decoded_text= token_ids_to_text(token_ids,tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\",\" \"))\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "LUJImRur1oiH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter,start_context,tokenizer):\n",
        "  train_losses, val_losses,track_tokens_seen=[],[],[]\n",
        "  tokens_seen,global_step=0,-1\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch,target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss= calc_loss_batch(input_batch,target_batch,model,device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen+=input_batch.numel()\n",
        "      global_step+=1\n",
        "\n",
        "      if global_step % eval_freq==0:\n",
        "        train_loss,val_loss= evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Ep {epoch+1} (Step{global_step}):\"\n",
        "        f\"Train Loss {train_loss:.3f}, Val Loss {val_loss:.3f}\"  )\n",
        "    generate_and_print_sample(model,tokenizer,device,start_context)\n",
        "  return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "1HGiOKM8xnHF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJlcBe7Ed2bJ",
        "outputId": "25f3aec5-e8a7-4e61-cf5a-2db533fa6892"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time= time.time()\n",
        "model= GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer= torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay=0.1)\n",
        "num_epochs=10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSg5XFss3VyO",
        "outputId": "207b6ce1-bdb5-46c5-ce57-e9a1a79f9cc7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step0):Train Loss 9.875, Val Loss 10.051\n",
            "Ep 1 (Step5):Train Loss 8.108, Val Loss 8.353\n",
            "Every effort moves you,,,,, the,,,,,,,,,,,,,,,,,,,,,,, the, the,,,,,,, the,,,,,,,,,,\n",
            "Ep 2 (Step10):Train Loss 6.816, Val Loss 7.078\n",
            "Ep 2 (Step15):Train Loss 6.094, Val Loss 6.582\n",
            "Every effort moves you, the the a a the\". \" a the the\", the the\" a a the\"\"\" a the the the\"\", the\" a the a the\". \"\", the\" a the a a a\n",
            "Ep 3 (Step20):Train Loss 5.567, Val Loss 6.534\n",
            "Ep 3 (Step25):Train Loss 5.648, Val Loss 6.454\n",
            "Every effort moves you, I had the I had of the I had the I had the I had the I had I, I had I had the I, and I, I had the I, I had the I had the-- I had the the I, I\n",
            "Ep 4 (Step30):Train Loss 5.081, Val Loss 6.399\n",
            "Ep 4 (Step35):Train Loss 4.404, Val Loss 6.374\n",
            "Every effort moves you know, and. \", and I had the first the to have to the to my the to have to have. Gisburn, and I had the to the to the to the he had the to the first to the he had I\n",
            "Ep 5 (Step40):Train Loss 3.980, Val Loss 6.332\n",
            "Every effort moves you know he was his pictures--and the first he had been the the last in the house.\"      \"Oh, and I saidburn's open count, I had the first time the donkey. \"Oh, I said\n",
            "Ep 6 (Step45):Train Loss 3.606, Val Loss 6.244\n",
            "Ep 6 (Step50):Train Loss 3.085, Val Loss 6.228\n",
            "Every effort moves you know,\" was not-stream stroke.     \"I turned back to my work, and went on groping and Mrs.                     \n",
            "Ep 7 (Step55):Train Loss 2.312, Val Loss 6.282\n",
            "Ep 7 (Step60):Train Loss 2.171, Val Loss 6.310\n",
            "Every effort moves you of Jack Gisburn--and I had been his pictures--his last word. Gisburn's an!  \" to see a little, on a later day, as a little his own sex his pictures--and he was with a\n",
            "Ep 8 (Step65):Train Loss 1.447, Val Loss 6.370\n",
            "Ep 8 (Step70):Train Loss 1.063, Val Loss 6.427\n",
            "Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I had been picture--I looked up, I felt to see a smile behind his close grayish beard--as if he had the donkey.      \n",
            "Ep 9 (Step75):Train Loss 0.855, Val Loss 6.479\n",
            "Ep 9 (Step80):Train Loss 0.561, Val Loss 6.605\n",
            "Every effort moves you?\" \"I looked up at the first time the irony. Gisburn's an--and by me!\"  \"Oh, in the moment--as Jack himself, I had again run over from Monte Carlo; and Mrs. Gis\n",
            "Ep 10 (Step85):Train Loss 0.415, Val Loss 6.715\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"    \"Oh, and back the window-curtains, and I turned, when Stroud laid in the first\n",
            "Training completed in 14.70 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids= generate_text_simple(\n",
        "    model=model,\n",
        "    idx= text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
      ],
      "metadata": {
        "id": "za2YvsLL7wsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842db35a-2c67-483f-cd08-3c0dbb836d99"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ],
      "metadata": {
        "id": "bXHRBIfEcKlL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits = torch.tensor(\n",
        "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "next_token_logits2 = next_token_logits/0.1 #sharpness\n",
        "next_token_logits3 = next_token_logits/5 #uniform distribution"
      ],
      "metadata": {
        "id": "WIHIEk_eiKcE"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "print(probas)\n",
        "probas2 = torch.softmax(next_token_logits2, dim=0)\n",
        "print(probas2)\n",
        "probas3 = torch.softmax(next_token_logits3, dim=0)\n",
        "print(probas3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSVo_2lCiKe0",
        "outputId": "8cfb831e-ea0c-4972-8a00-c249ab0d94b8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
            "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
            "tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
            "        2.9718e-38, 9.0133e-03, 2.8514e-22])\n",
            "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_id=torch.argmax(probas).item()\n",
        "print(next_token_id)\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw5wCjzZiKhV",
        "outputId": "3b1e3cf6-4a71-4568-b4f4-15b3647e3bcf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sampled_tokens(probas):\n",
        "  sample= [torch.multinomial(probas,num_samples=1).item() for i in range(1000)]\n",
        "  sample_ids= torch.bincount(torch.tensor(sample))\n",
        "  for i, freq in enumerate(sample_ids):\n",
        "    print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)\n",
        "print()\n",
        "print_sampled_tokens(probas2)\n",
        "print()\n",
        "print_sampled_tokens(probas3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gFbWy02iKkV",
        "outputId": "3b7aff53-87ef-49cb-fbba-2321d8fe4569"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 x closer\n",
            "2 x every\n",
            "0 x effort\n",
            "582 x forward\n",
            "5 x inches\n",
            "1 x moves\n",
            "1 x pizza\n",
            "363 x toward\n",
            "1 x you\n",
            "\n",
            "0 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "991 x forward\n",
            "0 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "9 x toward\n",
            "\n",
            "148 x closer\n",
            "68 x every\n",
            "41 x effort\n",
            "232 x forward\n",
            "92 x inches\n",
            "42 x moves\n",
            "47 x pizza\n",
            "239 x toward\n",
            "91 x you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits,temperature):\n",
        "  scaled_logits=logits/temperature\n",
        "  return torch.softmax(scaled_logits,dim=0)\n",
        "\n",
        "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
        "scaled_probas= [softmax_with_temperature(next_token_logits,T) for T in temperatures]"
      ],
      "metadata": {
        "id": "gc9S9kFuiKn2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x= torch.arange(len(vocab))\n",
        "bar_width=0.15\n",
        "fig,ax= plt.subplots(figsize=(5,3))\n",
        "for i,T in enumerate(temperatures):\n",
        "  rects= ax.bar(x+i*bar_width,scaled_probas[i],bar_width,label=f'Temperature={T}')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(),rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "gd5U6XAAoU9g",
        "outputId": "e8f78fa7-6c04-40a8-9edc-9737ac2ee92c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#top k sampling\n",
        "top_k=3\n",
        "top_logits, top_pos= torch.topk(next_token_logits,top_k)\n",
        "print(top_logits)\n",
        "print(top_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8-VyRgzoVF9",
        "outputId": "c9f81645-93b6-4671-fabc-7b1a46fa03c3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6.7500, 6.2800, 4.5100])\n",
            "tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits= torch.where(\n",
        "    condition= next_token_logits< top_logits[-1],\n",
        "    input= torch.tensor(float(\"-inf\")),\n",
        "    other=next_token_logits\n",
        ")\n",
        "print(new_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ni9qf3PoVJg",
        "outputId": "e1a4dc19-0b1b-4e5c-c5a7-979aafab26f3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probas= torch.softmax(new_logits,dim=0)\n",
        "print(topk_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4OdcyjAvi89",
        "outputId": "004d59a1-00c5-4eec-8753-cfd68365f3d5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge temperature scaling and top-k sampling\n",
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "uve1aQ1EvjVz"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "X3flXRyHvjZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175c272c-73ba-4e3f-db0f-61268b93a058"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you?\" I meant to do the picture for nothing--so it with equ out\n"
          ]
        }
      ]
    }
  ]
}